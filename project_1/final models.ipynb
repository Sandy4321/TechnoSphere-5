{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0507337014551999e-05, 7.2653298459750076e-05, 6.4151911726969464e-05, 6.8946497517926095e-05, 5.0461724781753044e-05, 4.39734400422145e-05, 3.2944587204322332e-05, 2.1918769041930604e-05, 1.6076653483810809e-05, 6.89731280693042e-06]\n"
     ]
    }
   ],
   "source": [
    "S = np.argsort(reviews.rating.value_counts().index)\n",
    "ratingCounts = reviews.rating.value_counts().values[S]\n",
    "proba = map(lambda x: 1.0/x, ratingCounts)\n",
    "print proba\n",
    "row_proba = map(lambda x: proba[int(x)-1], reviews.rating)\n",
    "row_proba /= sum(row_proba)\n",
    "idx = (np.random.choice(reviews.index, size=100000, replace=False, p=row_proba))\n",
    "reviewsNormed = reviews.loc[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 15)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsNormed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## учим на нормированной, тестим на обычной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_idx(y_train):\n",
    "    S = np.argsort(y_train.value_counts().index)\n",
    "    ratingCounts = y_train.value_counts().values[S]\n",
    "    proba = map(lambda x: 1.0/x, ratingCounts)\n",
    "    row_proba = map(lambda x: proba[int(x)-1], y_train)\n",
    "    row_proba /= sum(row_proba)\n",
    "    idx = (np.random.choice(y_train.index, size=100000, replace=False, p=row_proba))\n",
    "    return idx   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "linreg_accuracy_list = []\n",
    "linreg_mae_list = []\n",
    "linreg_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.stemmed[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.stemmed[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = norm_idx(y_train)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    linreg_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LinearRegression()),\n",
    "                    ])\n",
    "    linreg_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = linreg_text_clf_best_mae.predict(X_test).round()\n",
    "    y_pred = map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "    linreg_accuracy_list += [accuracy]\n",
    "    linreg_mae_list += [mae]\n",
    "    linreg_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'mean accuracy', np.mean(linreg_accuracy_list)\n",
    "print 'mean MAE', np.mean(linreg_mae_list)\n",
    "print 'mean MSE', np.mean(linreg_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,  10.   8.   1.]\n",
      "accuracy: 0.556939625605\n",
      "MAE: 0.980067402996\n",
      "MSE: 3.7323166549\n",
      "[[ 6591   145   213   140   215   219   208   159   106   252]\n",
      " [  803  1791   126    85   142   170   137   102    59    83]\n",
      " [  770    76  2008   122   183   290   236   156    64    78]\n",
      " [  512    59   104  1680   218   404   368   217    60    84]\n",
      " [  413    54    97   121  2352   525   635   425   133   135]\n",
      " [  336    61    72    84   257  2445  1040   834   246   272]\n",
      " [  281    63    59    72   247   527  3116  1734   722   657]\n",
      " [  346    62    77    63   268   347  1307  4800  2072  1993]\n",
      " [  360    36    31    45   193   305   724  2615  6195  4924]\n",
      " [  844    64   102    80   248   294   640  3057  6003 25044]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.80      0.68      8248\n",
      "        2.0       0.74      0.51      0.61      3498\n",
      "        3.0       0.70      0.50      0.58      3983\n",
      "        4.0       0.67      0.45      0.54      3706\n",
      "        5.0       0.54      0.48      0.51      4890\n",
      "        6.0       0.44      0.43      0.44      5647\n",
      "        7.0       0.37      0.42      0.39      7478\n",
      "        8.0       0.34      0.42      0.38     11335\n",
      "        9.0       0.40      0.40      0.40     15428\n",
      "       10.0       0.75      0.69      0.72     36376\n",
      "\n",
      "avg / total       0.57      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.   1.   5.]\n",
      "accuracy: 0.556472377695\n",
      "MAE: 0.980335822008\n",
      "MSE: 3.70377476662\n",
      "[[ 6488   145   246   179   222   249   191   210    82   226]\n",
      " [  794  1734   108   103   134   175   139   122    38    76]\n",
      " [  662    69  1942   123   187   301   227   160    64    66]\n",
      " [  447    49    95  1648   227   374   333   240    55   113]\n",
      " [  409    55    93   111  2346   596   569   433   136   147]\n",
      " [  325    56    80    83   263  2473  1008   869   201   232]\n",
      " [  305    28    63    80   259   526  3097  1907   642   627]\n",
      " [  283    59    74    96   284   367  1235  5050  1901  2183]\n",
      " [  342    26    52    46   218   243   742  2937  6013  4990]\n",
      " [  860    46   102    83   295   299   714  3351  5452 25184]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.79      0.68      8238\n",
      "        2.0       0.76      0.51      0.61      3423\n",
      "        3.0       0.68      0.51      0.58      3801\n",
      "        4.0       0.65      0.46      0.54      3581\n",
      "        5.0       0.53      0.48      0.50      4895\n",
      "        6.0       0.44      0.44      0.44      5590\n",
      "        7.0       0.38      0.41      0.39      7534\n",
      "        8.0       0.33      0.44      0.38     11532\n",
      "        9.0       0.41      0.39      0.40     15609\n",
      "       10.0       0.74      0.69      0.72     36386\n",
      "\n",
      "avg / total       0.57      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.   8.   8.]\n",
      "accuracy: 0.561144856793\n",
      "MAE: 0.97566334291\n",
      "MSE: 3.72856873018\n",
      "[[ 6533   126   219   152   235   247   174   186    83   219]\n",
      " [  737  1809   123    96   154   164   138   101    46    68]\n",
      " [  643    68  1996   115   226   293   215   149    50    91]\n",
      " [  468    66   110  1582   227   409   320   248    54    94]\n",
      " [  460    57   111    96  2260   617   718   437   109   161]\n",
      " [  339    35    78    71   237  2574  1101   828   184   231]\n",
      " [  345    46    69    56   226   511  3237  1835   678   671]\n",
      " [  345    49    90    78   288   350  1237  5049  1971  1978]\n",
      " [  343    35    43    35   222   210   741  2806  6244  4894]\n",
      " [  920    38   111    61   240   273   636  3311  5418 25161]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.80      0.68      8174\n",
      "        2.0       0.78      0.53      0.63      3436\n",
      "        3.0       0.68      0.52      0.59      3846\n",
      "        4.0       0.68      0.44      0.53      3578\n",
      "        5.0       0.52      0.45      0.48      5026\n",
      "        6.0       0.46      0.45      0.45      5678\n",
      "        7.0       0.38      0.42      0.40      7674\n",
      "        8.0       0.34      0.44      0.38     11435\n",
      "        9.0       0.42      0.40      0.41     15573\n",
      "       10.0       0.75      0.70      0.72     36169\n",
      "\n",
      "avg / total       0.58      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   1.   3.   1.]\n",
      "accuracy: 0.554653093281\n",
      "MAE: 0.984928769547\n",
      "MSE: 3.71679805943\n",
      "[[ 6429   135   181   129   249   286   184   193    95   238]\n",
      " [  717  1842    95    79   134   189   136    87    38    90]\n",
      " [  736    66  1957   145   220   288   260   153    56    77]\n",
      " [  458    63   120  1613   227   412   360   227    52   107]\n",
      " [  494    50   104   107  2304   557   665   405   124   196]\n",
      " [  363    49    74    93   262  2564  1017   899   214   291]\n",
      " [  307    28    80    68   258   550  3188  1865   673   651]\n",
      " [  328    39    92   102   276   311  1233  5015  1858  2067]\n",
      " [  361    33    44    40   174   263   779  2857  6089  4952]\n",
      " [  812    50    66    80   288   196   662  3329  5779 24791]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.58      0.79      0.67      8119\n",
      "        2.0       0.78      0.54      0.64      3407\n",
      "        3.0       0.70      0.49      0.58      3958\n",
      "        4.0       0.66      0.44      0.53      3639\n",
      "        5.0       0.52      0.46      0.49      5006\n",
      "        6.0       0.46      0.44      0.45      5826\n",
      "        7.0       0.38      0.42      0.39      7668\n",
      "        8.0       0.33      0.44      0.38     11321\n",
      "        9.0       0.41      0.39      0.40     15592\n",
      "       10.0       0.74      0.69      0.71     36053\n",
      "\n",
      "avg / total       0.57      0.55      0.56    100589\n",
      "\n",
      "====================\n",
      "Wall time: 9min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bayes_accuracy_list = []\n",
    "bayes_mae_list = []\n",
    "bayes_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = norm_idx(y_train)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    bayes_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.3, min_df=0.001)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MultinomialNB(alpha=0.2))\n",
    "                    ])\n",
    "    bayes_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = bayes_text_clf_best_mae.predict(X_test)\n",
    "    print 'predict done'\n",
    "    print y_pred\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    bayes_accuracy_list += [accuracy]\n",
    "    bayes_mae_list += [mae]\n",
    "    bayes_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.557302488344\n",
      "mean MAE 0.980248834366\n",
      "mean MSE 3.72036455278\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(bayes_accuracy_list)\n",
    "print 'mean MAE', np.mean(bayes_mae_list)\n",
    "print 'mean MSE', np.mean(bayes_mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bayes_text_clf.predict(data_train.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.527213353672\n",
      "MAE: 1.13884425157\n",
      "MSE: 4.62262119371\n"
     ]
    }
   ],
   "source": [
    "print \"accuracy:\", accuracy\n",
    "print \"MAE:\", mae\n",
    "print \"MSE:\", mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "logreg_accuracy_list = []\n",
    "logreg_mae_list = []\n",
    "logreg_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = norm_idx(y_train)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    logreg_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])\n",
    "    logreg_text_clf.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = logreg_text_clf.predict(X_test)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    logreg_accuracy_list += [accuracy]\n",
    "    logreg_mae_list += [mae]\n",
    "    logreg_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.558309059639\n",
      "mean MAE 0.93764228693\n",
      "mean MSE 3.3368907137\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(logreg_accuracy_list)\n",
    "print 'mean MAE', np.mean(logreg_mae_list)\n",
    "print 'mean MSE', np.mean(logreg_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## учим на обычной, тестим на обычной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "accuracy: 0.321864219746\n",
      "MAE: 1.19596576166\n",
      "MSE: 2.87674596626\n",
      "[[ 1531  1490  1703  1385   944   591   298   117    32    16]\n",
      " [  374   531   758   815   498   286   131    58    13     6]\n",
      " [  229   362   777  1018   730   412   247    67    26     5]\n",
      " [  114   215   560   801   840   563   341   131    35     7]\n",
      " [   67   113   371   868  1222  1155   647   283    85    27]\n",
      " [   24    66   167   488  1194  1688  1139   694   248    98]\n",
      " [    6    16    81   255   622  1488  2111  1636   979   405]\n",
      " [    3     4    33   101   348  1006  2289  3308  2617  1723]\n",
      " [    0     3     9    47   189   615  1888  3882  4883  3959]\n",
      " [    5     6    11    44   220   765  2624  6207 10976 15524]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.19      0.29      8107\n",
      "        2.0       0.19      0.15      0.17      3470\n",
      "        3.0       0.17      0.20      0.19      3873\n",
      "        4.0       0.14      0.22      0.17      3607\n",
      "        5.0       0.18      0.25      0.21      4838\n",
      "        6.0       0.20      0.29      0.23      5806\n",
      "        7.0       0.18      0.28      0.22      7599\n",
      "        8.0       0.20      0.29      0.24     11432\n",
      "        9.0       0.25      0.32      0.28     15475\n",
      "       10.0       0.71      0.43      0.53     36382\n",
      "\n",
      "avg / total       0.42      0.32      0.35    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.32146656195\n",
      "MAE: 1.18959329549\n",
      "MSE: 2.83394804601\n",
      "[[ 1529  1566  1714  1456   941   552   277   124    32    15]\n",
      " [  351   534   819   653   586   286   122    48    15     3]\n",
      " [  218   370   819   959   773   441   205    80    26     4]\n",
      " [   94   219   496   910   855   576   308   129    35    11]\n",
      " [   70   139   420   945  1254  1145   647   305    95    28]\n",
      " [   25    63   182   516  1150  1481  1176   667   249    95]\n",
      " [    7    20    65   241   630  1431  2067  1794   948   419]\n",
      " [    1     6    17    89   338  1003  2321  3269  2606  1695]\n",
      " [    3     0     6    34   182   631  1866  3903  4808  4177]\n",
      " [    1     4    14    33   197   803  2337  6461 10694 15665]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.67      0.19      0.29      8206\n",
      "        2.0       0.18      0.16      0.17      3417\n",
      "        3.0       0.18      0.21      0.19      3895\n",
      "        4.0       0.16      0.25      0.19      3633\n",
      "        5.0       0.18      0.25      0.21      5048\n",
      "        6.0       0.18      0.26      0.21      5604\n",
      "        7.0       0.18      0.27      0.22      7622\n",
      "        8.0       0.19      0.29      0.23     11345\n",
      "        9.0       0.25      0.31      0.27     15610\n",
      "       10.0       0.71      0.43      0.54     36209\n",
      "\n",
      "avg / total       0.42      0.32      0.34    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.319339092744\n",
      "MAE: 1.20003181262\n",
      "MSE: 2.88262136019\n",
      "[[ 1498  1520  1708  1451  1011   589   263   119    36    15]\n",
      " [  351   479   730   778   562   266   156    64    19     3]\n",
      " [  217   359   807  1016   802   432   199    82    25     6]\n",
      " [  110   214   511   819   831   630   293   108    46     4]\n",
      " [   60   142   432   838  1304  1233   615   283    84    24]\n",
      " [   27    71   219   493  1087  1626  1219   654   221    95]\n",
      " [    4     9    74   232   677  1383  2072  1733   968   428]\n",
      " [    4     1    23    79   324  1096  2329  3245  2612  1678]\n",
      " [    3     2     5    43   186   592  1871  3948  4775  4144]\n",
      " [    2     7    15    49   241   761  2541  6264 10816 15497]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.66      0.18      0.29      8210\n",
      "        2.0       0.17      0.14      0.15      3408\n",
      "        3.0       0.18      0.20      0.19      3945\n",
      "        4.0       0.14      0.23      0.17      3566\n",
      "        5.0       0.19      0.26      0.22      5015\n",
      "        6.0       0.19      0.28      0.23      5712\n",
      "        7.0       0.18      0.27      0.22      7580\n",
      "        8.0       0.20      0.28      0.23     11391\n",
      "        9.0       0.24      0.31      0.27     15569\n",
      "       10.0       0.71      0.43      0.53     36193\n",
      "\n",
      "avg / total       0.42      0.32      0.34    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.324339639523\n",
      "MAE: 1.18700851982\n",
      "MSE: 2.84021115629\n",
      "[[ 1461  1620  1667  1514   939   604   287   108    43    13]\n",
      " [  320   529   761   825   517   284   156    56    18     3]\n",
      " [  203   426   757   980   831   397   189    71    17     4]\n",
      " [   90   189   540   901   916   615   315    91    31    10]\n",
      " [   42   161   400   854  1347  1159   608   251    76    18]\n",
      " [   34    66   220   471  1128  1528  1156   668   250    98]\n",
      " [    5    14    73   241   709  1342  2099  1744   890   436]\n",
      " [    2     2    34    90   336  1006  2238  3397  2672  1678]\n",
      " [    1     3    12    34   174   599  1834  3817  4960  4114]\n",
      " [    0     7    10    50   220   738  2445  6307 10777 15646]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.68      0.18      0.28      8256\n",
      "        2.0       0.18      0.15      0.16      3469\n",
      "        3.0       0.17      0.20      0.18      3875\n",
      "        4.0       0.15      0.24      0.19      3698\n",
      "        5.0       0.19      0.27      0.22      4916\n",
      "        6.0       0.18      0.27      0.22      5619\n",
      "        7.0       0.19      0.28      0.22      7553\n",
      "        8.0       0.21      0.30      0.24     11455\n",
      "        9.0       0.25      0.32      0.28     15548\n",
      "       10.0       0.71      0.43      0.54     36200\n",
      "\n",
      "avg / total       0.43      0.32      0.35    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 13min, sys: 3.81 s, total: 13min 4s\n",
      "Wall time: 13min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "linreg2_accuracy_list = []\n",
    "linreg2_mae_list = []\n",
    "linreg2_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    linreg2_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LinearRegression()),\n",
    "                    ])\n",
    "    linreg2_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = linreg2_text_clf_best_mae.predict(X_test).round()\n",
    "    y_pred = map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "    linreg2_accuracy_list += [accuracy]\n",
    "    linreg2_mae_list += [mae]\n",
    "    linreg2_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.321752378491\n",
      "mean MAE 1.1931498474\n",
      "mean MSE 2.85838163219\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(linreg2_accuracy_list)\n",
    "print 'mean MAE', np.mean(linreg2_mae_list)\n",
    "print 'mean MSE', np.mean(linreg2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.  10.  10.]\n",
      "accuracy: 0.554513913052\n",
      "MAE: 1.1301335136\n",
      "MSE: 4.77293739872\n",
      "[[ 6393    16    41    39    73    83   107   191    71  1219]\n",
      " [ 1116  1242    39    22    69    73    94   103    43   521]\n",
      " [ 1068    14  1421    31   113   140   184   189    81   750]\n",
      " [  739    25    31  1141   133   235   283   265    92   689]\n",
      " [  644     7    24    34  1771   323   499   491   160  1050]\n",
      " [  455     3    22    18   135  1790   695   838   324  1470]\n",
      " [  343     1    20     8   106   198  1957  1403   676  2825]\n",
      " [  241     3     7     6    80    83   399  3237  1412  5979]\n",
      " [  123     2     1     2    28    55   146  1171  3632 10374]\n",
      " [  267     0     0     0    30    21   106   876  1645 33194]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.78      0.65      8233\n",
      "        2.0       0.95      0.37      0.54      3322\n",
      "        3.0       0.88      0.36      0.51      3991\n",
      "        4.0       0.88      0.31      0.46      3633\n",
      "        5.0       0.70      0.35      0.47      5003\n",
      "        6.0       0.60      0.31      0.41      5750\n",
      "        7.0       0.44      0.26      0.33      7537\n",
      "        8.0       0.37      0.28      0.32     11447\n",
      "        9.0       0.45      0.23      0.31     15534\n",
      "       10.0       0.57      0.92      0.70     36139\n",
      "\n",
      "avg / total       0.56      0.55      0.52    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,  10.   1.   1.]\n",
      "accuracy: 0.554464205828\n",
      "MAE: 1.14173517979\n",
      "MSE: 4.86329519132\n",
      "[[ 6345     6    37    25    88    86    96   161    91  1260]\n",
      " [ 1082  1284    31    26   105    78   102   118    59   560]\n",
      " [ 1036     5  1401    39    95   123   216   209    77   751]\n",
      " [  754    13    28  1229   122   185   264   301    84   723]\n",
      " [  629     2    16    29  1818   241   475   472   166  1067]\n",
      " [  423     8    19    25   129  1775   654   923   253  1483]\n",
      " [  317     0     4    13    96   164  1884  1518   629  2938]\n",
      " [  237     2     2     2    76    82   377  3218  1188  6219]\n",
      " [  162     5     0     2    24    61   138  1120  3366 10678]\n",
      " [  246     3     0     0    39    14    87   853  1470 33453]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.77      0.65      8195\n",
      "        2.0       0.97      0.37      0.54      3445\n",
      "        3.0       0.91      0.35      0.51      3952\n",
      "        4.0       0.88      0.33      0.48      3703\n",
      "        5.0       0.70      0.37      0.48      4915\n",
      "        6.0       0.63      0.31      0.42      5692\n",
      "        7.0       0.44      0.25      0.32      7563\n",
      "        8.0       0.36      0.28      0.32     11403\n",
      "        9.0       0.46      0.22      0.29     15556\n",
      "       10.0       0.57      0.93      0.70     36165\n",
      "\n",
      "avg / total       0.57      0.55      0.51    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.  10.   1.]\n",
      "accuracy: 0.555368877313\n",
      "MAE: 1.12532185428\n",
      "MSE: 4.73937508077\n",
      "[[ 6347    22    25    28    74   130   129   163    93  1209]\n",
      " [ 1141  1311    22    31    79    91   107   113    68   556]\n",
      " [  979    12  1399    34    84   162   206   185    79   619]\n",
      " [  755    23    25  1126   118   210   305   279    93   658]\n",
      " [  623     1    16    17  1684   300   522   480   171  1122]\n",
      " [  409    12    15    22   115  1765   742   854   297  1427]\n",
      " [  327     6     4     8   105   217  1965  1420   687  2866]\n",
      " [  220     3     1     0    68    96   456  3145  1276  5990]\n",
      " [  160     0     0     1    32    68   171  1063  3542 10656]\n",
      " [  243     0     1     2    16    32    72   854  1552 33580]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.57      0.77      0.65      8220\n",
      "        2.0       0.94      0.37      0.53      3519\n",
      "        3.0       0.93      0.37      0.53      3759\n",
      "        4.0       0.89      0.31      0.46      3592\n",
      "        5.0       0.71      0.34      0.46      4936\n",
      "        6.0       0.57      0.31      0.40      5658\n",
      "        7.0       0.42      0.26      0.32      7605\n",
      "        8.0       0.37      0.28      0.32     11255\n",
      "        9.0       0.45      0.23      0.30     15693\n",
      "       10.0       0.57      0.92      0.71     36352\n",
      "\n",
      "avg / total       0.56      0.56      0.52    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,  10.   5.   1.]\n",
      "accuracy: 0.55601507123\n",
      "MAE: 1.12653471055\n",
      "MSE: 4.75104633707\n",
      "[[ 6337    10    27    19    85    85   105   170    74  1219]\n",
      " [ 1168  1272    31    16    75   105   109   120    64   518]\n",
      " [ 1046     8  1427    17   134   161   182   165    56   690]\n",
      " [  769    18    30  1078   109   230   281   297   109   655]\n",
      " [  641     8    15    15  1808   258   456   542   172  1048]\n",
      " [  428     1    13     5   123  1792   621   927   313  1418]\n",
      " [  309     3    10     1   104   201  1944  1507   712  2858]\n",
      " [  252     1     6     9    87    87   374  3340  1380  5982]\n",
      " [  173     0     7     1    30    65   137  1037  3604 10365]\n",
      " [  254     0     0     0    39    27    76   862  1743 33327]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.78      0.65      8131\n",
      "        2.0       0.96      0.37      0.53      3478\n",
      "        3.0       0.91      0.37      0.52      3886\n",
      "        4.0       0.93      0.30      0.46      3576\n",
      "        5.0       0.70      0.36      0.48      4963\n",
      "        6.0       0.60      0.32      0.41      5641\n",
      "        7.0       0.45      0.25      0.33      7649\n",
      "        8.0       0.37      0.29      0.33     11518\n",
      "        9.0       0.44      0.23      0.30     15419\n",
      "       10.0       0.57      0.92      0.71     36328\n",
      "\n",
      "avg / total       0.57      0.56      0.52    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 7min 42s, sys: 4.86 s, total: 7min 46s\n",
      "Wall time: 7min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bayes2_accuracy_list = []\n",
    "bayes2_mae_list = []\n",
    "bayes2_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    bayes2_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.3, min_df=0.001)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MultinomialNB(alpha=0.2))\n",
    "                    ])\n",
    "    bayes2_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = bayes2_text_clf_best_mae.predict(X_test)\n",
    "    print 'predict done'\n",
    "    print y_pred\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    bayes2_accuracy_list += [accuracy]\n",
    "    bayes2_mae_list += [mae]\n",
    "    bayes2_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.555090516856\n",
      "mean MAE 1.13093131456\n",
      "mean MSE 4.78166350197\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(bayes2_accuracy_list)\n",
    "print 'mean MAE', np.mean(bayes2_mae_list)\n",
    "print 'mean MSE', np.mean(bayes2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "accuracy: 0.574993289525\n",
      "MAE: 0.915070236308\n",
      "MSE: 3.24486772908\n",
      "[[ 5986   459   412   369   275   198   112    47    40   249]\n",
      " [  714  1807   236   223   177   101    58    33    17    73]\n",
      " [  633   211  1935   308   277   212   109    60    25    60]\n",
      " [  348   189   275  1620   347   335   201    78    22   103]\n",
      " [  356   179   312   383  2356   563   415   201    80   166]\n",
      " [  201   132   256   325   487  2606   844   458   144   245]\n",
      " [  205    96   141   204   429   846  3305  1145   549   673]\n",
      " [  164   110   131   183   279   600  1606  4310  1534  2355]\n",
      " [  204    98   153   158   226   412   994  2022  5197  6178]\n",
      " [  434   208   190   210   278   362   855  2083  3103 28716]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.73      0.69      8147\n",
      "        2.0       0.52      0.53      0.52      3439\n",
      "        3.0       0.48      0.51      0.49      3830\n",
      "        4.0       0.41      0.46      0.43      3518\n",
      "        5.0       0.46      0.47      0.46      5011\n",
      "        6.0       0.42      0.46      0.44      5698\n",
      "        7.0       0.39      0.44      0.41      7593\n",
      "        8.0       0.41      0.38      0.40     11272\n",
      "        9.0       0.49      0.33      0.39     15642\n",
      "       10.0       0.74      0.79      0.76     36439\n",
      "\n",
      "avg / total       0.57      0.57      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.572497986857\n",
      "MAE: 0.923480698685\n",
      "MSE: 3.27914583106\n",
      "[[ 6105   430   488   319   257   230   117    50    34   224]\n",
      " [  762  1738   233   225   168   119    67    41    18    62]\n",
      " [  657   252  1928   265   276   243   153    49    26    84]\n",
      " [  447   181   263  1677   337   347   189    93    31    83]\n",
      " [  330   203   275   323  2303   597   439   194    70   159]\n",
      " [  209   128   247   291   495  2553   858   464   158   227]\n",
      " [  203   120   158   231   377   820  3215  1206   518   698]\n",
      " [  242   104   135   175   268   619  1639  4375  1541  2414]\n",
      " [  194   116   125   116   187   438   979  2116  5168  6070]\n",
      " [  481   190   173   194   238   381   831  2259  2959 28525]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.63      0.74      0.68      8254\n",
      "        2.0       0.50      0.51      0.50      3433\n",
      "        3.0       0.48      0.49      0.48      3933\n",
      "        4.0       0.44      0.46      0.45      3648\n",
      "        5.0       0.47      0.47      0.47      4893\n",
      "        6.0       0.40      0.45      0.43      5630\n",
      "        7.0       0.38      0.43      0.40      7546\n",
      "        8.0       0.40      0.38      0.39     11512\n",
      "        9.0       0.49      0.33      0.40     15509\n",
      "       10.0       0.74      0.79      0.76     36231\n",
      "\n",
      "avg / total       0.57      0.57      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.574675163288\n",
      "MAE: 0.933412202129\n",
      "MSE: 3.37184980465\n",
      "[[ 6175   440   388   329   274   171   107    54    27   223]\n",
      " [  682  1800   241   198   187   144    58    39    16    86]\n",
      " [  676   226  1959   250   267   223   150    49    36    72]\n",
      " [  398   171   227  1712   327   358   241   114    36    90]\n",
      " [  411   179   285   329  2354   585   392   177    75   160]\n",
      " [  258   143   209   312   470  2494   886   455   155   288]\n",
      " [  203   109   135   217   402   820  3186  1273   550   723]\n",
      " [  224   108   118   197   294   528  1516  4448  1479  2523]\n",
      " [  218   110   121   143   234   360  1009  2084  5249  6075]\n",
      " [  519   197   200   201   279   380   865  2108  2917 28429]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.63      0.75      0.69      8188\n",
      "        2.0       0.52      0.52      0.52      3451\n",
      "        3.0       0.50      0.50      0.50      3908\n",
      "        4.0       0.44      0.47      0.45      3674\n",
      "        5.0       0.46      0.48      0.47      4947\n",
      "        6.0       0.41      0.44      0.43      5670\n",
      "        7.0       0.38      0.42      0.40      7618\n",
      "        8.0       0.41      0.39      0.40     11435\n",
      "        9.0       0.50      0.34      0.40     15603\n",
      "       10.0       0.74      0.79      0.76     36095\n",
      "\n",
      "avg / total       0.57      0.57      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.576454681923\n",
      "MAE: 0.917028700951\n",
      "MSE: 3.27150085993\n",
      "[[ 6194   418   421   285   301   173    91    43    44   220]\n",
      " [  702  1787   243   222   172   134    60    34    14    73]\n",
      " [  552   235  2025   301   280   229   111    68    36    80]\n",
      " [  399   185   264  1746   346   345   172    71    41    95]\n",
      " [  351   206   296   361  2285   621   423   181    71   171]\n",
      " [  215   121   237   337   491  2621   822   449   170   280]\n",
      " [  232   109   157   238   415   790  3211  1205   541   699]\n",
      " [  204    91   142   199   264   631  1546  4322  1508  2497]\n",
      " [  193   111   108   125   215   335   978  1958  5271  6154]\n",
      " [  496   190   171   207   298   348   869  2034  3083 28523]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.76      0.70      8190\n",
      "        2.0       0.52      0.52      0.52      3441\n",
      "        3.0       0.50      0.52      0.51      3917\n",
      "        4.0       0.43      0.48      0.45      3664\n",
      "        5.0       0.45      0.46      0.46      4966\n",
      "        6.0       0.42      0.46      0.44      5743\n",
      "        7.0       0.39      0.42      0.40      7597\n",
      "        8.0       0.42      0.38      0.40     11404\n",
      "        9.0       0.49      0.34      0.40     15448\n",
      "       10.0       0.74      0.79      0.76     36219\n",
      "\n",
      "avg / total       0.57      0.58      0.57    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 13min 17s, sys: 4.61 s, total: 13min 22s\n",
      "Wall time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg2_accuracy_list = []\n",
    "logreg2_mae_list = []\n",
    "logreg2_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    logreg2_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])\n",
    "    logreg2_text_clf.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = logreg2_text_clf.predict(X_test)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    logreg2_accuracy_list += [accuracy]\n",
    "    logreg2_mae_list += [mae]\n",
    "    logreg2_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.574655280398\n",
      "mean MAE 0.922247959518\n",
      "mean MSE 3.29184105618\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(logreg2_accuracy_list)\n",
    "print 'mean MAE', np.mean(logreg2_mae_list)\n",
    "print 'mean MSE', np.mean(logreg2_mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])\n",
    "\n",
    "with open('logreg_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(logreg_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2_text_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LinearRegression\n",
      "  normed train\n",
      "    mean accuracy 0.280552545507\n",
      "    mean MAE 1.3439019177\n",
      "    mean MSE 3.36363568581\n",
      "  not normed train\n",
      "    mean accuracy 0.321752378491\n",
      "    mean MAE 1.1931498474\n",
      "    mean MSE 2.85838163219\n",
      "MultinomialNB\n",
      "  normed train\n",
      "    mean accuracy 0.55507809005\n",
      "    mean MAE 0.976856316297\n",
      "    mean MSE 3.68161528597\n",
      "  not normed train\n",
      "    mean accuracy 0.555090516856\n",
      "    mean MAE 1.13093131456\n",
      "    mean MSE 4.78166350197\n",
      "LogisticRegression\n",
      "  normed train\n",
      "    mean accuracy 0.558309059639\n",
      "    mean MAE 0.93764228693\n",
      "    mean MSE 3.3368907137\n",
      "  not normed train\n",
      "    mean accuracy 0.574655280398\n",
      "    mean MAE 0.922247959518\n",
      "    mean MSE 3.29184105618\n"
     ]
    }
   ],
   "source": [
    "print 'LinearRegression'\n",
    "print '  normed train'\n",
    "print '    mean accuracy', np.mean(linreg_accuracy_list)\n",
    "print '    mean MAE', np.mean(linreg_mae_list)\n",
    "print '    mean MSE', np.mean(linreg_mse_list)\n",
    "print '  not normed train'\n",
    "print '    mean accuracy', np.mean(linreg2_accuracy_list)\n",
    "print '    mean MAE', np.mean(linreg2_mae_list)\n",
    "print '    mean MSE', np.mean(linreg2_mse_list)\n",
    "\n",
    "print 'MultinomialNB'\n",
    "print '  normed train'\n",
    "print '    mean accuracy', np.mean(bayes_accuracy_list)\n",
    "print '    mean MAE', np.mean(bayes_mae_list)\n",
    "print '    mean MSE', np.mean(bayes_mse_list)\n",
    "print '  not normed train'\n",
    "print '    mean accuracy', np.mean(bayes2_accuracy_list)\n",
    "print '    mean MAE', np.mean(bayes2_mae_list)\n",
    "print '    mean MSE', np.mean(bayes2_mse_list)\n",
    "\n",
    "print 'LogisticRegression'\n",
    "print '  normed train'\n",
    "print '    mean accuracy', np.mean(logreg_accuracy_list)\n",
    "print '    mean MAE', np.mean(logreg_mae_list)\n",
    "print '    mean MSE', np.mean(logreg_mse_list)\n",
    "print '  not normed train'\n",
    "print '    mean accuracy', np.mean(logreg2_accuracy_list)\n",
    "print '    mean MAE', np.mean(logreg2_mae_list)\n",
    "print '    mean MSE', np.mean(logreg2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test =pd.read_csv('data/data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train.stemmed\n",
    "y_train = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = data_test.stemmed\n",
    "y_test = data_test.rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.4, max_features=None, min_df=0.003,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ..._idf=False)), ('clf', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = norm_idx(y_train)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "linreg_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', LinearRegression()),\n",
    "                ])\n",
    "linreg_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('linreg_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(linreg_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('linreg_text_clf.pickle', 'rb') as handle:\n",
    "    linreg_text_clf.pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = linreg_text_clf.predict(X_test).round()\n",
    "y_pred = map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.204644706018\n",
      "MAE: 1.7646412355\n",
      "MSE: 5.16349018133\n",
      "[[ 882  874  929  990  759  344  153   67    0    0]\n",
      " [ 167  212  298  412  316  170   99    0   20    0]\n",
      " [ 174  242  221  399  407  222   63   27    0    0]\n",
      " [  76  115  230  377  281  217   89   38   20    0]\n",
      " [  23   79  235  345  365  357  268   51   11    0]\n",
      " [  30  111  150  312  299  516  324   94   50    1]\n",
      " [   0    2  140  147  477  521  624  379  111   76]\n",
      " [  20   17   67  120  220  539  833  703  369  177]\n",
      " [   0    0   32   95  248  543  966  936  742  597]\n",
      " [   0    0   13  161  426 1011 2062 2880 2378 2434]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.64      0.18      0.28      4998\n",
      "        2.0       0.13      0.13      0.13      1694\n",
      "        3.0       0.10      0.13      0.11      1755\n",
      "        4.0       0.11      0.26      0.16      1443\n",
      "        5.0       0.10      0.21      0.13      1734\n",
      "        6.0       0.12      0.27      0.16      1887\n",
      "        7.0       0.11      0.25      0.16      2477\n",
      "        8.0       0.14      0.23      0.17      3065\n",
      "        9.0       0.20      0.18      0.19      4159\n",
      "       10.0       0.74      0.21      0.33     11365\n",
      "\n",
      "avg / total       0.41      0.20      0.23     34577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linreg_accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "linreg_mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "linreg_mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", linreg_accuracy\n",
    "print \"MAE:\", linreg_mae\n",
    "print \"MSE:\", linreg_mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train.stemmed\n",
    "y_train = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.4, max_features=None, min_df=0.003,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ..._idf=False)), ('clf', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "linreg2_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', LinearRegression()),\n",
    "                ])\n",
    "linreg2_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('linreg2_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(linreg2_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('linreg2_text_clf.pickle', 'rb') as handle:\n",
    "    linreg2_text_clf.pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = linreg2_text_clf.predict(X_test).round()\n",
    "y_pred = map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.234577898603\n",
      "MAE: 1.65960031235\n",
      "MSE: 4.94588888568\n",
      "[[ 669  515  989  795  870  640  414   82   24    0]\n",
      " [ 113  193  237  324  387  212  152   66   10    0]\n",
      " [  75  128  262  401  329  320  133   82   15   10]\n",
      " [  50   83  189  268  336  276  139   86   16    0]\n",
      " [  43   50  108  318  368  417  219  150   61    0]\n",
      " [  15   57  112  158  500  428  353  149   82   33]\n",
      " [   0   14   46  191  309  528  565  538  227   59]\n",
      " [  10   10   38   62  209  447  722  787  493  287]\n",
      " [   0    0   10   19  141  263  835 1002 1052  837]\n",
      " [   0    0   20   73  120  504 1406 2649 3074 3519]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.69      0.13      0.22      4998\n",
      "        2.0       0.18      0.11      0.14      1694\n",
      "        3.0       0.13      0.15      0.14      1755\n",
      "        4.0       0.10      0.19      0.13      1443\n",
      "        5.0       0.10      0.21      0.14      1734\n",
      "        6.0       0.11      0.23      0.14      1887\n",
      "        7.0       0.11      0.23      0.15      2477\n",
      "        8.0       0.14      0.26      0.18      3065\n",
      "        9.0       0.21      0.25      0.23      4159\n",
      "       10.0       0.74      0.31      0.44     11365\n",
      "\n",
      "avg / total       0.42      0.23      0.26     34577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linreg2_accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "linreg2_mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "linreg2_mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", linreg2_accuracy\n",
    "print \"MAE:\", linreg2_mae\n",
    "print \"MSE:\", linreg2_mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train.stemmed\n",
    "y_train = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000L,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = norm_idx(y_train)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = norm_idx(y_train)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "bayes_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.3, min_df=0.001)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MultinomialNB(alpha=0.2))\n",
    "                    ])\n",
    "bayes_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bayes_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(bayes_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bayes_text_clf.pickle', 'rb') as handle:\n",
    "    bayes_text_clf.pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bayes_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.395407351708\n",
      "MAE: 1.61798305232\n",
      "MSE: 7.05211556815\n"
     ]
    }
   ],
   "source": [
    "bayes_accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "bayes_mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "bayes_mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", bayes_accuracy\n",
    "print \"MAE:\", bayes_mae\n",
    "print \"MSE:\", bayes_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train.stemmed\n",
    "y_train = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "bayes2_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.3, min_df=0.001)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MultinomialNB(alpha=0.2))\n",
    "                    ])\n",
    "bayes2_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bayes2_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(bayes2_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bayes2_text_clf.pickle', 'rb') as handle:\n",
    "    bayes2_text_clf.pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bayes2_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.45400121468\n",
      "MAE: 1.62451918906\n",
      "MSE: 7.78387367325\n"
     ]
    }
   ],
   "source": [
    "bayes2_accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "bayes2_mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "bayes2_mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", bayes2_accuracy\n",
    "print \"MAE:\", bayes2_mae\n",
    "print \"MSE:\", bayes2_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train.stemmed\n",
    "y_train = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = norm_idx(y_train)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "logreg_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])\n",
    "logreg_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('logreg_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(logreg_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('logreg_text_clf.pickle', 'rb') as handle:\n",
    "    logreg_text_clf.pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.398386210487\n",
      "MAE: 1.45394337276\n",
      "MSE: 5.62868380716\n"
     ]
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "logreg_mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "logreg_mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", logreg_accuracy\n",
    "print \"MAE:\", logreg_mae\n",
    "print \"MSE:\", logreg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train.review_text\n",
    "y_train = data_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "logreg2_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2'))\n",
    "                            ])\n",
    "logreg2_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('logreg2_text_clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(logreg2_text_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('logreg2_text_clf.pickle', 'rb') as handle:\n",
    "    logreg2_text_clf.pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg2_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.402059172282\n",
      "MAE: 1.56679295485\n",
      "MSE: 6.58000983313\n"
     ]
    }
   ],
   "source": [
    "logreg2_accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "logreg2_mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "logreg2_mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", logreg2_accuracy\n",
    "print \"MAE:\", logreg2_mae\n",
    "print \"MSE:\", logreg2_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linreg_best_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LinearRegression()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_best_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.001, max_df=0.3)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_best_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1266px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
